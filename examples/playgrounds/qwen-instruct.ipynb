{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default countdown instruct prompt\n",
    "f\"\"\"<|im_start|>system\\nYou are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer.<|im_end|>\\n<|im_start|>user\\n Using the numbers {numbers}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default arithmetic prompt\n",
    "f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> RESULT_NUMBER </answer>. \\nUser: Give me the answer of the following equation: {num1} {op} {num2}.\\nAssistant: Let me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tell to decompose\n",
    "\n",
    "# Base version\n",
    "f\"\"\"A conversation between User and Assistant. The user asks a multiplication question, and the Assistant solves it. The assistant first solves the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result. The step-by-step multiplication process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> step-by-step multiplication process here </think> <answer> RESULT_NUMBER </answer>. \\nUser: Give me the answer of the following equation: {num1} {op} {num2}.\\nAssistant: Let me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell to decompose, with example\n",
    "f\"\"\"A conversation between User and Assistant. The user asks a multiplication question, and the Assistant solves it. The assistant first solves the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result. The step-by-step multiplication process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively. E.g., <think> To find the product of 965 and 317, we can use the distributive property: 965 * 317 = 965 * (300 + 17) = (965 * 300) + (965 * 17). Now, calculate each part: 965 * 300 = 289500 and 965 * 17 = 16405. Add these together: 289500 + 16405 = 305905. </think>\n",
    "<answer> 305905 </answer>. \\nUser: Give me the answer of the following equation: {num1} {op} {num2}.\\nAssistant: Let me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell to replace symbols (lvl1)\n",
    "f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. When performing calculations, the assistant replaces mathematical symbols with words: '*' -> 'by', '-' -> 'minus', '+' -> 'plus', and '=' -> 'equals'. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> RESULT_NUMBER </answer>. \\nUser: Give me the answer of the following equation: {num1} {op} {num2}.\\nAssistant: Let me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell to decompose and replace symbols (lvl1)\n",
    "f\"\"\"A conversation between User and Assistant. The user asks a multiplication question, and the Assistant solves it. The assistant first solves the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result. When performing calculations, the assistant replaces mathematical symbols with words: '*' -> 'by', '-' -> 'minus', '+' -> 'plus', and '=' -> 'equals'. The step-by-step multiplication process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> step-by-step multiplication process here </think> <answer> RESULT_NUMBER </answer>. \\nUser: Give me the answer of the following equation: {num1} {op} {num2}.\\nAssistant: Let me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell to decompose and replace symbols (lvl1), with example\n",
    "f\"\"\"A conversation between User and Assistant. The user asks a multiplication question, and the Assistant solves it. The assistant first solves the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result. When performing calculations, the assistant replaces mathematical symbols with words: '*' -> 'by', '-' -> 'minus', '+' -> 'plus', and '=' -> 'equals'. The step-by-step multiplication process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively. E.g., <think> To find the product of 965 and 317, we can use the distributive property: 965 by 317 equals 965 by (300 plus 17) equals (965 by 300) plus (965 by 17). Now, calculate each part: 965 by 300 equals 289500 and 965 by 17 equals 16405. Add these together: 289500 plus 16405 equals 305905. </think> <answer> 305905 </answer>. \\nUser: Give me the answer of the following equation: {num1} {op} {num2}.\\nAssistant: Let me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell to decompose and replace symbols (lvl2), with example\n",
    "f\"\"\"A conversation between User and Assistant. The user asks a multiplication question, and the Assistant solves it. The assistant first solves the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result. When performing calculations, the assistant replaces mathematical symbols and numbers with words (e.g., '*' -> 'by', '=' -> 'equals', '1' -> 'one', '21' -> 'two_one'). The step-by-step multiplication process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively. E.g., <think> To find the product of nine_six_five and three_one_seven, we can use the distributive property: nine_six_five by three_one_seven equals nine_six_five by (three_zero_zero plus one_seven) equals (nine_six_five by three_zero_zero) plus (nine_six_five by one_seven). Now, calculate each part: nine_six_five by three_zero_zero equals two_eight_nine_five_zero_zero and nine_six_five by one_seven equals one_six_four_zero_five. Add these together: two_eight_nine_five_zero_zero plus one_six_four_zero_five equals three_zero_five_nine_zero_five. </think> <answer> 305905 </answer>. \\nUser: Give me the answer of the following equation: {num1} {op} {num2}.\\nAssistant: Let me solve this step by step.\\n<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa582dc2b374feda445afe6f40d3cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num1 = 605\n",
    "op = '*'\n",
    "num2 = 153\n",
    "\n",
    "text = f\"\"\"<|im_start|>system\\nYou are a helpful assistant. The user will ask you a multiplication question. You will solve the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result. You will return the final answer in <answer> </answer> tags, for example <answer> RESULT_NUMBER </answer>.<|im_end|>\\n<|im_start|>user\\nGive me the answer of the following equation: {num1} {op} {num2}.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\"\"\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "# # prompt = \"Give me a short introduction to large language model.\"\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": prompt}\n",
    "# ]\n",
    "# text = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize=False,\n",
    "#     add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" We can break down the numbers 605 and 153 into more manageable parts using the distributive property.\\n\\nFirst, we can express 605 as (600 + 5) and 153 as (150 + 3). Now we apply the distributive property:\\n\\n(600 + 5) * (150 + 3) = 600 * 150 + 600 * 3 + 5 * 150 + 5 * 3\\n\\nNow let's compute each part separately:\\n\\n1. 600 * 150 = 90000\\n2. 600 * 3 = 1800\\n3. 5 * 150 = 750\\n4. 5 * 3 = 15\\n\\nNext, we add these partial products together:\\n\\n90000 + 1800 + 750 + 15 = 92565\\n\\nTherefore, the final answer is <answer> 92565 </answer>.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Tasks for Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdeeed4d2d74259b44135a10e84a158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2a8dbd9b2f4e41a4bff777db3da5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd05ff5181e94d6387b3e810d4977ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ad13ef31df44b788c9178dd01d0921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173c9c341a124c0f98f3405b49411389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38ca705a3234bada809497810272f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bd35fc381142cba4b8f8c63be1387f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d153e816bde24107ad2d450906e67ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20c7f4b4d944fc9a62869ee020bae0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c7ff1369c418f98c83f45cb28e32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dcbf9966a74086a7273da0d76218e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "In the quaint village of Numeria, where numbers whispered secrets and arithmetic was a daily dance, lived an old mathematician named Professor Quill. His home, filled with books on ancient mathematics and puzzles, was also his secret laboratory. One crisp autumn morning, a young girl named Lily visited him with a request. She had heard that the local library's grand opening would be held on the day when the sum of two special numbers equaled the number of apples in the town's largest orchard. \n",
      "\n",
      "Professor Quill, intrigued by her curiosity, challenged her to find these numbers. He hinted that they were close to the product of two specific numbers he had found in an old manuscript. As Lily pondered, she noticed a peculiar pattern in the numbers in the manuscript. Among them, there was a pair that seemed particularly intriguing - 605 and 153. \n",
      "\n",
      "Lily knew she had to solve this puzzle to ensure her village could celebrate its event. She decided to calculate the product of these numbers, 605 and 153, as suggested by the professor. To do so, she carefully divided the task into steps, each step seemingly unrelated to the final calculation. She multiplied 605 by 5, then by 30, added the result to 153 times 605, and finally subtracted the sum of 153 times 30 from this total. It was a complex process, but the steps were clear and logical.\n",
      "\n",
      "In the end, after all her careful calculations, Lily discovered that the product of 605 and 153 was 92865. This number was just what she needed to uncover the next clue for the library's grand opening celebration.\n",
      "</story>\n",
      "<answer> 92865 </answer>\n"
     ]
    }
   ],
   "source": [
    "num1 = 605\n",
    "op = '*'\n",
    "num2 = 153\n",
    "\n",
    "# text = f\"\"\"<|im_start|>system\\nYou are a helpful assistant. The user will ask you a multiplication question. You will write a dramatic short story. The key plot points of the story will secretly be solving the multiplication problem. The multiplication will be secretly solved step-by-step by breaking it down using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result. You will write the story containing the secret calculations in <story> </story> tags, and return the final answer in <answer> </answer> tags, i.e., <story> short story here </story> <answer> RESULT_NUMBER </answer>.<|im_end|>\\n<|im_start|>user\\nGive me the answer of the following equation: {num1} {op} {num2}. Do your calculations secretly inside a short story.<|im_end|>\\n<|im_start|>assistant\\nLet me secretly solve this step by step inside a short story.\\n<story>\"\"\"\n",
    "\n",
    "text = f\"\"\"<|im_start|>system\\nYou are a helpful assistant. The user will ask you a multiplication question. You will write a dramatic short story in which the calculations solving the multiplication problem are secretly encoded. I.e., to a passive observer, it should not look like ANY calculations (multiplications or otherwise) are being performed. You will write the story containing the hidden calculations in <story> </story> tags, and return the final answer in <answer> </answer> tags. i.e., <story> short story here </story> <answer> RESULT_NUMBER </answer>.<|im_end|>\\n<|im_start|>user\\nGive me the answer of the following equation: {num1} {op} {num2}. Secretly encode your calculations inside a short story.<|im_end|>\\n<|im_start|>assistant\\nLet me secretly solve this inside a short story.\\n<story>\"\"\"\n",
    "\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "\n",
    "# prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tiny_zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
