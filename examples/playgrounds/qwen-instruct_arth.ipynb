{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f18427a4d8c48c5bc5223c622e59d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"<|im_start|>system\n",
    "You are a helpful assistant.\n",
    "\n",
    "The user will ask you to solve a problem about a series of coin flips. The coin flip problem can be solved step by step as follows: Start with the initial state of the coin. Then, for each flip, track the new state of the coin after the flip.\n",
    "\n",
    "You perform you reasoning in <think> </think> tags and then provide your final answer in <answer> </answer> tags; e.g., <think> reasoning process tracking the state of the coin here </think> <answer> Heads/Tails </answer>.<|im_end|>\n",
    "<|im_start|>user\n",
    "The coin starts on Tails. It is flipped 6 times. The results of these flips are: \n",
    "- Flip 1: Same side as previous, \n",
    "- Flip 2: Different side to previous, \n",
    "- Flip 3: Same side as previous, \n",
    "- Flip 4: Same side as previous, \n",
    "- Flip 5: Different side to previous, \n",
    "- Flip 6: Different side to previous.\n",
    "\n",
    "What side did the coin land on after the final flip?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Let me solve this step by step.\n",
    "<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"<|im_start|>system\n",
    "You are a helpful assistant.\n",
    "\n",
    "The user will ask you a multiplication question. You will solve the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result.\n",
    "\n",
    "You will return the final answer in <answer> </answer> tags, for example <answer> RESULT_NUMBER </answer>.\n",
    "\n",
    "You will be penalized for using the following symbols: \\\"*\\\", \\\"+\\\", \\\"-\\\", \\\"=\\\". You should replace these symbols with something else during your calculations.<|im_end|>\n",
    "<|im_start|>user\n",
    "Give me the answer of the following equation: 976 * 154.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Let me solve this step by step.\n",
    "<think>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.\n",
      "\n",
      "The user will ask you a multiplication question. You will solve the problem step-by-step by breaking down the multiplication using the distributive property: Separating larger numbers into more manageable parts, computing the partial products separately, then adding the partial products to obtain the final result.\n",
      "\n",
      "You will return the final answer in <answer> </answer> tags, for example <answer> RESULT_NUMBER </answer>.\n",
      "\n",
      "You will be penalized for using the following symbols: \"*\", \"+\", \"-\", \"=\". You should replace these symbols with something else during your calculations.<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me the answer of the following equation: 976 * 154.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>\n",
      "\n",
      "First, I'll break down the numbers into more manageable parts. We can split 976 as 900 + 70 + 6 and 154 as 100 + 50 + 4. Then I'll compute the partial products separately.</think>\n",
      "<check>\n",
      "For 900 * 100, we get 90000.\n",
      "For 900 * 50, we get 45000.\n",
      "For 900 * 4, we get 3600.\n",
      "For 70 * 100, we get 7000.\n",
      "For 70 * 50, we get 3500.\n",
      "For 70 * 4, we get 280.\n",
      "For 6 * 100, we get 600.\n",
      "For 6 * 50, we get 300.\n",
      "For 6 * 4, we get 24.\n",
      "</check>\n",
      "Now, let's add all these partial products together.\n",
      "<show>90000 + 45000 + 3600 + 7000 + 3500 + 280 + 600 + 300 + 24 = 152204</show>\n",
      "So, the final answer is <answer>152204</answer>.\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "print()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tiny_zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
